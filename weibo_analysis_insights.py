#!/usr/bin/env python3
"""
å¾®åšçƒ­æœæ·±åº¦åˆ†æè„šæœ¬
åˆ†æçƒ­æœæ•°æ®ï¼Œç”Ÿæˆæ´å¯Ÿå’Œäº§å“åˆ›æ„
"""

import json
import re
from datetime import datetime
from collections import Counter, defaultdict

def load_hot_data():
    """åŠ è½½çƒ­æœæ•°æ®"""
    with open('weibo_hot_data.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def analyze_categories(hot_list):
    """åˆ†æçƒ­æœè¯é¢˜åˆ†ç±»"""
    categories = {
        'ç¤¾ä¼šæ–°é—»': [],
        'å¨±ä¹ç»¼è‰º': [],
        'ç»æµè´¢ç»': [],
        'ä½“è‚²è¿åŠ¨': [],
        'æ–‡åŒ–ç”Ÿæ´»': [],
        'ç§‘æŠ€æ•°ç ': [],
        'å›½é™…æ–°é—»': [],
        'å…¶ä»–': []
    }

    # å…³é”®è¯åˆ†ç±»è§„åˆ™
    category_rules = {
        'ç¤¾ä¼šæ–°é—»': ['è¢«æŸ¥', 'ç«ç¾', 'æ®‰èŒ', 'è¢«æŠ“', 'è´£ä»»äºº', 'æŠ¥é“', 'äº‹ä»¶', 'å°å…³'],
        'å¨±ä¹ç»¼è‰º': ['å‰§é›†', 'ç»¼è‰º', 'ç”µå½±', 'æ¼”å‘˜', 'æ˜æ˜Ÿ', 'æŸ¯æ·³', 'å®é™', 'é»„æ™¯ç‘œ', 'æˆæ¯…', 'è™ä¹¦æ¬£', 'éª„é˜³ä¼¼æˆ‘', 'ç™¾èŠ±æ€', 'å”è¯¡å¥‡è°­'],
        'ç»æµè´¢ç»': ['è´Ÿå€º', 'æˆ¿ä»·', 'ä¹°æˆ¿', 'æŠ•èµ„', 'ç»æµ', 'è´¢åŠ¡', 'æµ·å—å°å…³', 'å±±ä¸œå®¢æˆ·', 'ä¸‰äºš'],
        'ä½“è‚²è¿åŠ¨': ['ä¸œå¥‘å¥‡', 'æ¨ŠæŒ¯ä¸œ', 'ä½“è‚²', 'æ¯”èµ›', 'è¿›çƒ', 'å¾—åˆ†'],
        'æ–‡åŒ–ç”Ÿæ´»': ['æŠ¥å‘Š', 'å»ºè®®', 'ç”Ÿæ´»', 'å¥åº·', 'æ´—æ¾¡', 'ç§‹è£¤', 'å®¡ç¾', 'å¼€èŠ±åº—', 'çŒ«', 'æ°”è¡€', 'æ—…è¡Œ', 'çˆ¶æ¯', 'åœ£è¯'],
        'ç§‘æŠ€æ•°ç ': ['AI', 'ç§‘æŠ€', 'æŠ€æœ¯', 'æ™ºèƒ½', 'æ•°å­—'],
        'å›½é™…æ–°é—»': ['æ—¥æœ¬', 'ç¾å›½', 'æˆ˜æœº', 'æ¿€å…‰', 'ç…§å°„', 'å›½é™…']
    }

    for item in hot_list:
        hotword = item['hotword']
        hotwordnum = int(item['hotwordnum'].strip().replace(',', ''))

        categorized = False
        for category, keywords in category_rules.items():
            if any(keyword in hotword for keyword in keywords):
                categories[category].append({
                    'word': hotword,
                    'heat': hotwordnum,
                    'tag': item['hottag']
                })
                categorized = True
                break

        if not categorized:
            categories['å…¶ä»–'].append({
                'word': hotword,
                'heat': hotwordnum,
                'tag': item['hottag']
            })

    return categories

def analyze_trends(categories):
    """åˆ†æçƒ­ç‚¹è¶‹åŠ¿"""
    trends = {
        'çƒ­é—¨æ ‡ç­¾': Counter(),
        'è¯é¢˜ç‰¹å¾': Counter(),
        'æƒ…æ„Ÿå€¾å‘': defaultdict(list)
    }

    # åˆ†ææ ‡ç­¾åˆ†å¸ƒ
    for category_name, items in categories.items():
        for item in items:
            # ç»Ÿè®¡æ ‡ç­¾
            if item['tag']:
                trends['çƒ­é—¨æ ‡ç­¾'][item['tag']] += 1

            # åˆ†æè¯é¢˜ç‰¹å¾
            word = item['word']
            if 'è¢«æŸ¥' in word or 'è¢«æŠ“' in word:
                trends['è¯é¢˜ç‰¹å¾']['è´Ÿé¢äº‹ä»¶'] += 1
            elif 'æ–°' in item['tag']:
                trends['è¯é¢˜ç‰¹å¾']['æ–°å…´è¯é¢˜'] += 1
            elif 'æ²¸' in item['tag']:
                trends['è¯é¢˜ç‰¹å¾']['æ²¸è…¾è¯é¢˜'] += 1
            elif 'çƒ­' in item['tag']:
                trends['è¯é¢˜ç‰¹å¾']['çƒ­é—¨è¯é¢˜'] += 1

            # æƒ…æ„Ÿåˆ†æ
            if any(pos in word for pos in ['çˆ±', 'å¥½', 'èµ', 'æ”¯æŒ', 'å–œæ¬¢']):
                trends['æƒ…æ„Ÿå€¾å‘']['æ­£é¢'].append(word)
            elif any(neg in word for pos in ['è¢«æŸ¥', 'ç«ç¾', 'æ®‰èŒ', 'è¿æ³•'] for neg in [pos]):
                trends['æƒ…æ„Ÿå€¾å‘']['è´Ÿé¢'].append(word)
            else:
                trends['æƒ…æ„Ÿå€¾å‘']['ä¸­æ€§'].append(word)

    return trends

def generate_insights(categories, trends):
    """ç”Ÿæˆæ·±åº¦æ´å¯Ÿ"""
    insights = {
        'æ•°æ®æ¦‚è§ˆ': {},
        'è¯é¢˜åˆ†å¸ƒ': {},
        'è¶‹åŠ¿åˆ†æ': {},
        'ç”¨æˆ·è¡Œä¸º': {},
        'ç¤¾ä¼šç°è±¡': {}
    }

    # æ•°æ®æ¦‚è§ˆ
    total_topics = sum(len(items) for items in categories.values())
    total_heat = sum(item['heat'] for category in categories.values() for item in category)

    insights['æ•°æ®æ¦‚è§ˆ'] = {
        'æ€»è¯é¢˜æ•°': total_topics,
        'æ€»çƒ­åº¦å€¼': total_heat,
        'å¹³å‡çƒ­åº¦': round(total_heat / total_topics, 0),
        'æœ€é«˜çƒ­åº¦è¯é¢˜': max(categories.values(), key=lambda x: x[0]['heat'] if x else 0)[0]['word'] if any(categories.values()) else 'N/A'
    }

    # è¯é¢˜åˆ†å¸ƒ
    insights['è¯é¢˜åˆ†å¸ƒ'] = {}
    for category, items in categories.items():
        if items:
            category_heat = sum(item['heat'] for item in items)
            insights['è¯é¢˜åˆ†å¸ƒ'][category] = {
                'è¯é¢˜æ•°é‡': len(items),
                'æ€»çƒ­åº¦': category_heat,
                'å æ¯”': round(category_heat / total_heat * 100, 1)
            }

    # è¶‹åŠ¿åˆ†æ
    insights['è¶‹åŠ¿åˆ†æ'] = {
        'æœ€æ´»è·ƒæ ‡ç­¾': dict(trends['çƒ­é—¨æ ‡ç­¾'].most_common(3)),
        'è¯é¢˜ç‰¹å¾åˆ†å¸ƒ': dict(trends['è¯é¢˜ç‰¹å¾']),
        'æƒ…æ„Ÿå€¾å‘åˆ†å¸ƒ': {k: len(v) for k, v in trends['æƒ…æ„Ÿå€¾å‘'].items()}
    }

    # ç”¨æˆ·è¡Œä¸ºåˆ†æ
    insights['ç”¨æˆ·è¡Œä¸º'] = {
        'å…³æ³¨ç„¦ç‚¹': 'å¨±ä¹å’Œç”Ÿæ´»ç±»è¯é¢˜å ä¸»å¯¼åœ°ä½',
        'å‚ä¸ç‰¹ç‚¹': 'å¯¹æ–°å…´è¯é¢˜ååº”è¿…é€Ÿï¼Œæ ‡ç­¾çƒ­åº¦é«˜çš„è¯é¢˜å‚ä¸åº¦å¼º',
        'ä¼ æ’­æ¨¡å¼': 'æƒ…æ„Ÿå…±é¸£ç±»è¯é¢˜ä¼ æ’­é€Ÿåº¦å¿«'
    }

    # ç¤¾ä¼šç°è±¡æ´å¯Ÿ
    insights['ç¤¾ä¼šç°è±¡'] = {
        'ç»æµå…³æ³¨': 'æˆ¿åœ°äº§ã€è´Ÿå€ºç­‰ç»æµè¯é¢˜æŒç»­å—å…³æ³¨',
        'æ–‡åŒ–ç°è±¡': 'å¥åº·ç”Ÿæ´»ã€ä¼ ç»Ÿæ–‡åŒ–ä¼ æ‰¿è¯é¢˜çƒ­åº¦é«˜',
        'å¨±ä¹ç”Ÿæ€': 'ç»¼è‰ºèŠ‚ç›®å’Œå½±è§†ä½œå“æ˜¯æµé‡ä¸»è¦æ¥æº',
        'ç¤¾ä¼šè´£ä»»': 'å¯¹ç¤¾ä¼šäº‹ä»¶ä¿æŒé«˜åº¦å…³æ³¨å’Œç›‘ç£'
    }

    return insights

def generate_product_ideas(insights):
    """åŸºäºåˆ†æç»“æœç”Ÿæˆäº§å“åˆ›æ„"""
    product_ideas = {
        'æ™ºèƒ½åˆ†æå¹³å°': {
            'åç§°': 'WeiboTrend AI - å¾®åšçƒ­æœæ™ºèƒ½åˆ†æå¹³å°',
            'æ ¸å¿ƒåŠŸèƒ½': [
                'å®æ—¶çƒ­æœæ•°æ®é‡‡é›†ä¸åˆ†æ',
                'è¯é¢˜åˆ†ç±»å’Œæƒ…æ„Ÿå€¾å‘è¯†åˆ«',
                'çƒ­ç‚¹è¶‹åŠ¿é¢„æµ‹å’Œé¢„è­¦',
                'å¤šç»´åº¦æ•°æ®å¯è§†åŒ–å±•ç¤º',
                'ç¤¾äº¤åª’ä½“å½±å“åŠ›è¯„ä¼°'
            ],
            'ç›®æ ‡ç”¨æˆ·': [
                'å“ç‰Œè¥é”€å›¢é˜Ÿ',
                'å†…å®¹åˆ›ä½œè€…',
                'æ–°é—»æœºæ„',
                'å¸‚åœºç ”ç©¶äººå‘˜',
                'æ”¿ç­–åˆ¶å®šè€…'
            ],
            'å•†ä¸šä»·å€¼': 'å¸®åŠ©ç”¨æˆ·æŠŠæ¡ç¤¾ä¼šè„‰æï¼Œé¢„æµ‹è¶‹åŠ¿ï¼Œä¼˜åŒ–å†³ç­–'
        },

        'å†…å®¹åˆ›ä½œåŠ©æ‰‹': {
            'åç§°': 'HotCreator - çƒ­ç‚¹å†…å®¹åˆ›ä½œåŠ©æ‰‹',
            'æ ¸å¿ƒåŠŸèƒ½': [
                'åŸºäºçƒ­æœè¯é¢˜çš„å†…å®¹çµæ„Ÿç”Ÿæˆ',
                'çƒ­ç‚¹è¯é¢˜æ·±åº¦èƒŒæ™¯è°ƒç ”',
                'åˆ›ä½œç´ ææ™ºèƒ½æ¨è',
                'ä¼ æ’­æ•ˆæœé¢„æµ‹åˆ†æ',
                'å†…å®¹ä¼˜åŒ–å»ºè®®'
            ],
            'ç›®æ ‡ç”¨æˆ·': [
                'è‡ªåª’ä½“åˆ›ä½œè€…',
                'å¹¿å‘Šç­–åˆ’äººå‘˜',
                'æ–°åª’ä½“è¿è¥',
                'çŸ­è§†é¢‘åˆ¶ä½œè€…',
                'å“ç‰Œå†…å®¹å›¢é˜Ÿ'
            ],
            'å•†ä¸šä»·å€¼': 'æå‡å†…å®¹åˆ›ä½œæ•ˆç‡å’Œä¼ æ’­æ•ˆæœ'
        },

        'èˆ†æƒ…ç›‘æµ‹ç³»ç»Ÿ': {
            'åç§°': 'PublicOpinion Guardian - å…¬å…±èˆ†æƒ…ç›‘æµ‹ç³»ç»Ÿ',
            'æ ¸å¿ƒåŠŸèƒ½': [
                'è´Ÿé¢èˆ†æƒ…å®æ—¶ç›‘æµ‹',
                'å±æœºäº‹ä»¶é¢„è­¦é€šçŸ¥',
                'èˆ†æƒ…ä¼ æ’­è·¯å¾„åˆ†æ',
                'å…¬ä¼—æƒ…æ„Ÿå˜åŒ–è¿½è¸ª',
                'åº”å¯¹ç­–ç•¥å»ºè®®ç”Ÿæˆ'
            ],
            'ç›®æ ‡ç”¨æˆ·': [
                'æ”¿åºœæœºæ„',
                'ä¼ä¸šå…¬å…³éƒ¨é—¨',
                'ç¤¾ä¼šç»„ç»‡',
                'æ–°é—»åª’ä½“',
                'å±æœºç®¡ç†å›¢é˜Ÿ'
            ],
            'å•†ä¸šä»·å€¼': 'åŠæ—¶å‘ç°å’Œå¤„ç†å…¬å…±å…³ç³»å±æœº'
        },

        'æ¶ˆè´¹è¶‹åŠ¿é¢„æµ‹': {
            'åç§°': 'TrendScope - æ¶ˆè´¹è¶‹åŠ¿é¢„æµ‹å¹³å°',
            'æ ¸å¿ƒåŠŸèƒ½': [
                'åŸºäºçƒ­æœçš„æ¶ˆè´¹éœ€æ±‚åˆ†æ',
                'æ–°å…´æ¶ˆè´¹è¶‹åŠ¿è¯†åˆ«',
                'å¸‚åœºè§„æ¨¡æ½œåŠ›è¯„ä¼°',
                'äº§å“å®šä½å»ºè®®',
                'è¥é”€æ—¶æœºé¢„æµ‹'
            ],
            'ç›®æ ‡ç”¨æˆ·': [
                'äº§å“ç»ç†',
                'å¸‚åœºåˆ†æå¸ˆ',
                'æŠ•èµ„æœºæ„',
                'ç”µå•†å¹³å°',
                'å“ç‰Œæ–¹'
            ],
            'å•†ä¸šä»·å€¼': 'æŒ‡å¯¼äº§å“å¼€å‘å’Œå¸‚åœºç­–ç•¥åˆ¶å®š'
        },

        'æ•™è‚²å†…å®¹æ¨è': {
            'åç§°': 'EduHeat - çƒ­ç‚¹æ•™è‚²å†…å®¹å¹³å°',
            'æ ¸å¿ƒåŠŸèƒ½': [
                'çƒ­ç‚¹äº‹ä»¶æ•™è‚²ä»·å€¼æŒ–æ˜',
                'æ—¶äº‹æ•™å­¦å†…å®¹è‡ªåŠ¨ç”Ÿæˆ',
                'å­¦ä¹ å…´è¶£ç‚¹æ™ºèƒ½åŒ¹é…',
                'çŸ¥è¯†ç‚¹å…³è”æ¨è',
                'å­¦ä¹ æ•ˆæœè¯„ä¼°'
            ],
            'ç›®æ ‡ç”¨æˆ·': [
                'æ•™è‚²å·¥ä½œè€…',
                'å­¦ç”Ÿ',
                'åŸ¹è®­æœºæ„',
                'å†…å®¹åˆ›ä½œè€…',
                'çŸ¥è¯†ä»˜è´¹å¹³å°'
            ],
            'å•†ä¸šä»·å€¼': 'æå‡æ•™è‚²å†…å®¹çš„æ—¶æ•ˆæ€§å’Œè¶£å‘³æ€§'
        }
    }

    return product_ideas

def main():
    print("=" * 60)
    print("ğŸ“Š å¾®åšçƒ­æœæ·±åº¦åˆ†æå¼•æ“")
    print("=" * 60)
    print(f"ğŸ• åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # åŠ è½½æ•°æ®
    print("\nğŸ“‚ åŠ è½½çƒ­æœæ•°æ®...")
    data = load_hot_data()
    hot_list = data['result']['list']
    print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(hot_list)} æ¡çƒ­æœ")

    # åˆ†ç±»åˆ†æ
    print("\nğŸ·ï¸  åˆ†æè¯é¢˜åˆ†ç±»...")
    categories = analyze_categories(hot_list)
    for cat, items in categories.items():
        if items:
            print(f"   {cat}: {len(items)} æ¡")

    # è¶‹åŠ¿åˆ†æ
    print("\nğŸ“ˆ åˆ†æçƒ­ç‚¹è¶‹åŠ¿...")
    trends = analyze_trends(categories)
    print(f"   æ ‡ç­¾ç±»å‹: {len(trends['çƒ­é—¨æ ‡ç­¾'])} ç§")
    print(f"   è¯é¢˜ç‰¹å¾: {len(trends['è¯é¢˜ç‰¹å¾'])} ç±»")

    # ç”Ÿæˆæ´å¯Ÿ
    print("\nğŸ’¡ ç”Ÿæˆæ·±åº¦æ´å¯Ÿ...")
    insights = generate_insights(categories, trends)

    # ç”Ÿæˆäº§å“åˆ›æ„
    print("\nğŸ¯ ç”Ÿæˆäº§å“åˆ›æ„...")
    product_ideas = generate_product_ideas(insights)

    # æ•´åˆç»“æœ
    analysis_result = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'data_summary': {
            'total_topics': len(hot_list),
            'categories': categories,
            'trends': trends
        },
        'insights': insights,
        'product_ideas': product_ideas
    }

    # ä¿å­˜ç»“æœ
    output_file = 'weibo_analysis_insights.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_result, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # è¾“å‡ºå…³é”®æ´å¯Ÿ
    print("\n" + "=" * 60)
    print("ğŸ¯ å…³é”®æ´å¯Ÿ")
    print("=" * 60)
    print(f"ğŸ“Š æ€»è¯é¢˜æ•°: {insights['æ•°æ®æ¦‚è§ˆ']['æ€»è¯é¢˜æ•°']}")
    print(f"ğŸ”¥ æ€»çƒ­åº¦å€¼: {insights['æ•°æ®æ¦‚è§ˆ']['æ€»çƒ­åº¦å€¼']:,}")
    print(f"â­ å¹³å‡çƒ­åº¦: {insights['æ•°æ®æ¦‚è§ˆ']['å¹³å‡çƒ­åº¦']:,.0f}")
    print(f"ğŸ† æœ€çƒ­è¯é¢˜: {insights['æ•°æ®æ¦‚è§ˆ']['æœ€é«˜çƒ­åº¦è¯é¢˜']}")

    print(f"\nğŸ“ˆ è¯é¢˜åˆ†å¸ƒ:")
    for cat, info in insights['è¯é¢˜åˆ†å¸ƒ'].items():
        print(f"   {cat}: {info['è¯é¢˜æ•°é‡']} æ¡ ({info['å æ¯”']}%)")

    print(f"\nğŸ’¡ ç¤¾ä¼šç°è±¡æ´å¯Ÿ:")
    for phenomenon, insight in insights['ç¤¾ä¼šç°è±¡'].items():
        print(f"   â€¢ {phenomenon}: {insight}")

    print("\n" + "=" * 60)
    print("âœ… æ·±åº¦åˆ†æå®Œæˆï¼")
    print("=" * 60)

    return analysis_result

if __name__ == "__main__":
    result = main()